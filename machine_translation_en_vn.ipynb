{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine_translation_en_vn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VODQOAwKjelC",
        "outputId": "e0fffd22-b358-444f-9a0b-9beb07f76155"
      },
      "source": [
        "pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.1+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2 MB)\n",
            "\u001b[K     |█████████████▌                  | 834.1 MB 1.4 MB/s eta 0:13:17tcmalloc: large alloc 1147494400 bytes == 0x55a151dd4000 @  0x7ff3e8882615 0x55a118b0402c 0x55a118be417a 0x55a118b06e4d 0x55a118bf8c0d 0x55a118b7b0d8 0x55a118b75c35 0x55a118b0873a 0x55a118b7af40 0x55a118b75c35 0x55a118b0873a 0x55a118b7793b 0x55a118bf9a56 0x55a118b76fb3 0x55a118bf9a56 0x55a118b76fb3 0x55a118bf9a56 0x55a118b76fb3 0x55a118b08b99 0x55a118b4be79 0x55a118b077b2 0x55a118b7ae65 0x55a118b75c35 0x55a118b0873a 0x55a118b7793b 0x55a118b75c35 0x55a118b0873a 0x55a118b76b0e 0x55a118b0865a 0x55a118b76d67 0x55a118b75c35\n",
            "\u001b[K     |█████████████████               | 1055.7 MB 1.3 MB/s eta 0:12:00tcmalloc: large alloc 1434370048 bytes == 0x55a19642a000 @  0x7ff3e8882615 0x55a118b0402c 0x55a118be417a 0x55a118b06e4d 0x55a118bf8c0d 0x55a118b7b0d8 0x55a118b75c35 0x55a118b0873a 0x55a118b7af40 0x55a118b75c35 0x55a118b0873a 0x55a118b7793b 0x55a118bf9a56 0x55a118b76fb3 0x55a118bf9a56 0x55a118b76fb3 0x55a118bf9a56 0x55a118b76fb3 0x55a118b08b99 0x55a118b4be79 0x55a118b077b2 0x55a118b7ae65 0x55a118b75c35 0x55a118b0873a 0x55a118b7793b 0x55a118b75c35 0x55a118b0873a 0x55a118b76b0e 0x55a118b0865a 0x55a118b76d67 0x55a118b75c35\n",
            "\u001b[K     |█████████████████████▋          | 1336.2 MB 1.1 MB/s eta 0:09:38tcmalloc: large alloc 1792966656 bytes == 0x55a11b25c000 @  0x7ff3e8882615 0x55a118b0402c 0x55a118be417a 0x55a118b06e4d 0x55a118bf8c0d 0x55a118b7b0d8 0x55a118b75c35 0x55a118b0873a 0x55a118b7af40 0x55a118b75c35 0x55a118b0873a 0x55a118b7793b 0x55a118bf9a56 0x55a118b76fb3 0x55a118bf9a56 0x55a118b76fb3 0x55a118bf9a56 0x55a118b76fb3 0x55a118b08b99 0x55a118b4be79 0x55a118b077b2 0x55a118b7ae65 0x55a118b75c35 0x55a118b0873a 0x55a118b7793b 0x55a118b75c35 0x55a118b0873a 0x55a118b76b0e 0x55a118b0865a 0x55a118b76d67 0x55a118b75c35\n",
            "\u001b[K     |███████████████████████████▎    | 1691.1 MB 1.2 MB/s eta 0:04:06tcmalloc: large alloc 2241208320 bytes == 0x55a186044000 @  0x7ff3e8882615 0x55a118b0402c 0x55a118be417a 0x55a118b06e4d 0x55a118bf8c0d 0x55a118b7b0d8 0x55a118b75c35 0x55a118b0873a 0x55a118b7af40 0x55a118b75c35 0x55a118b0873a 0x55a118b7793b 0x55a118bf9a56 0x55a118b76fb3 0x55a118bf9a56 0x55a118b76fb3 0x55a118bf9a56 0x55a118b76fb3 0x55a118b08b99 0x55a118b4be79 0x55a118b077b2 0x55a118b7ae65 0x55a118b75c35 0x55a118b0873a 0x55a118b7793b 0x55a118b75c35 0x55a118b0873a 0x55a118b76b0e 0x55a118b0865a 0x55a118b76d67 0x55a118b75c35\n",
            "\u001b[K     |████████████████████████████████| 1982.2 MB 1.3 MB/s eta 0:00:01tcmalloc: large alloc 1982177280 bytes == 0x55a20b9a6000 @  0x7ff3e88811e7 0x55a118b39ae7 0x55a118b0402c 0x55a118be417a 0x55a118b06e4d 0x55a118bf8c0d 0x55a118b7b0d8 0x55a118b75c35 0x55a118b0873a 0x55a118b76d67 0x55a118b75c35 0x55a118b0873a 0x55a118b76d67 0x55a118b75c35 0x55a118b0873a 0x55a118b76d67 0x55a118b75c35 0x55a118b0873a 0x55a118b76d67 0x55a118b75c35 0x55a118b0873a 0x55a118b76d67 0x55a118b0865a 0x55a118b76d67 0x55a118b75c35 0x55a118b0873a 0x55a118b7793b 0x55a118b75c35 0x55a118b0873a 0x55a118b7793b 0x55a118b75c35\n",
            "tcmalloc: large alloc 2477727744 bytes == 0x55a281c00000 @  0x7ff3e8882615 0x55a118b0402c 0x55a118be417a 0x55a118b06e4d 0x55a118bf8c0d 0x55a118b7b0d8 0x55a118b75c35 0x55a118b0873a 0x55a118b76d67 0x55a118b75c35 0x55a118b0873a 0x55a118b76d67 0x55a118b75c35 0x55a118b0873a 0x55a118b76d67 0x55a118b75c35 0x55a118b0873a 0x55a118b76d67 0x55a118b75c35 0x55a118b0873a 0x55a118b76d67 0x55a118b0865a 0x55a118b76d67 0x55a118b75c35 0x55a118b0873a 0x55a118b7793b 0x55a118b75c35 0x55a118b0873a 0x55a118b7793b 0x55a118b75c35 0x55a118b08dd1\n",
            "\u001b[K     |████████████████████████████████| 1982.2 MB 1.2 kB/s \n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/torchvision/\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.9.1+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.6 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting torchaudio===0.8.1\n",
            "  Downloading torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0+cu102\n",
            "    Uninstalling torchvision-0.10.0+cu102:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu102\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.8.1+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.1+cu111 torchaudio-0.8.1 torchvision-0.9.1+cu111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rD2ZkO2k5JE",
        "outputId": "7dd83d22-7812-4e4d-9a84-af7bd5a711ab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfV3xrE5lESx",
        "outputId": "6d3dbe20-5120-4c1c-a4a7-ffdb21e18d8d"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.init import xavier_normal_\n",
        "import random\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_SyFuYZlOI1"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.init import xavier_normal_\n",
        "import random\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "class EncoderLSTM(torch.nn.Module):\n",
        "    # class Encoder using Bidirectional LSTM\n",
        "    # Pha mã hoá của kiến trúc seq2seq sử dụng kiến trúc của mạng LSTM 2 chiều\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
        "        super(EncoderLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.tag = True\n",
        "        # embedding matrix shape [input_size, embedding_size]\n",
        "        # Ma trận nhúng có kích thước bằng [kích thước từ điển tiếng Anh, độ dài vec-tơ nhúng]\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        # lstm input [embedding_size, hidden_size, num_layers]\n",
        "        # Mạng LSTM có đầu vào [độ dài vec-tơ nhúng, tầng ẩn, số LSTM xếp chồng =2]\n",
        "        self.LSTM = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # forward LSTM\n",
        "        # quá trình lan truyền thẳng\n",
        "        # input x src English shape [seq_len, batch_size]\n",
        "        # Ma trận x có đầu vào [độ dài của câu, số lượng câu]\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "        # embedding shape [seq_len, batch_size, embedding_size]\n",
        "        # Ma trận nhúng Embedding có kích thước [độ dài câu, số lượng câu, kích thước nhúng]\n",
        "        outputs, (hidden_state, cell_state) = self.LSTM(embedding)\n",
        "        # output Encoder return hidden state and cell state shape [num_layer, batch_size, hidden_size]\n",
        "        # Kết quả của pha mã hoá là hidden_state và cell_state với kích thước [số lớp LSTM, số lượng câu, tầng ẩn]\n",
        "        return hidden_state, cell_state\n",
        "\n",
        "\n",
        "class DecoderLSTM(torch.nn.Module):\n",
        "    # class Decoder using Bidirectional LSTM\n",
        "    # Pha giải mã của kiến trúc seq2seq sử dụng kiến trúc của mạng LSTM 2 chiều\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p, output_size):\n",
        "        super(DecoderLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.output_size = output_size\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        # embedding matrix shape [input_size, embedding_size]\n",
        "        # Ma trận nhúng có kích thước bằng [kích thước từ điển tiếng Việt, độ dài vec-tơ nhúng]\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        # lstm input [embedding_size, hidden_size, num_layers]\n",
        "        # Mạng LSTM có đầu vào [độ dài vec-tơ nhúng, tầng ẩn, số LSTM xếp chồng =2]\n",
        "        self.LSTM = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
        "        # linear network shape (hidden_size, output_size)\n",
        "        # Mạng tuyến tính có kích thước [hidden_size, output_size]\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden_state, cell_state):\n",
        "        # forward LSTM\n",
        "        # x shape [1, batch_size]\n",
        "        # vector x có kích thước [1, bath_size]\n",
        "        x = x.unsqueeze(0)\n",
        "        # embedding shape [1, batch_size, embedding_dim]\n",
        "        # Ma trận nhúng embedding tương ứng có kích thước [1, số lượng câu, kích thước nhúng]\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "        # outputs shape [1, batch_size, hidden_size] and hs, cs shape [num_layer, batch_size, hidden_size]\n",
        "        # đầu ra out_puts có kích thước [1, số lượng batch, kích thước tầng ẩn] và các trạng thái h_s, c_s\n",
        "        outputs, (hidden_state, cell_state) = self.LSTM(embedding, (hidden_state, cell_state))\n",
        "        # predictions shape [1, batch_size, output_size]\n",
        "        # dự đoán đi qua mạng tuyến tính lan truyền thẳng được kích thước [số câu, kích thước đầu ra]\n",
        "        predictions = self.fc(outputs)\n",
        "        # predictions shape [batch_size, output_size]\n",
        "        predictions = predictions.squeeze(0)\n",
        "\n",
        "        return predictions, hidden_state, cell_state\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    # Seq2Seq model with the Encoder-Decoder architecture\n",
        "    def __init__(self, Encoder_LSTM, Decoder_LSTM):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.Encoder_LSTM = Encoder_LSTM\n",
        "        self.Decoder_LSTM = Decoder_LSTM\n",
        "\n",
        "    def forward(self, source, target, tfr=0.5):\n",
        "        # Shape sentences source english : (10, 32) [(Sentence length English + some padding), Number of Sentences]\n",
        "        batch_size = source.shape[1]\n",
        "        # Shape sentences target vietnamese: (14, 32) [(Sentence length VietNamese + some padding), Number of Sentences]\n",
        "        target_len = target.shape[0]\n",
        "        target_vocab_size = 10004\n",
        "        # Shape outputs (14, 32, 5766)\n",
        "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "        # Shape --> (hs, cs) (2, 32, 1024) ,(2, 32, 1024) [num_layers, batch_size size, hidden_size]\n",
        "        hidden_state, cell_state = self.Encoder_LSTM(source)\n",
        "        # Shape of x (32 elements)\n",
        "        x = target[0]  # Trigger token <SOS>\n",
        "        for i in range(1, target_len):\n",
        "            # Shape --> output (32, 5766)\n",
        "            output, hidden_state, cell_state = self.Decoder_LSTM(x, hidden_state, cell_state)\n",
        "            outputs[i] = output\n",
        "            best_guess = output.argmax(1)  # 0th dimension is batch size, 1st dimension is word embedding\n",
        "            # Either pass the next word correctly from the dataset or use the earlier predicted word\n",
        "            x = target[i] if random.random() < tfr else best_guess\n",
        "        # Shape --> outputs (14, 32, 5766)\n",
        "        return outputs\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okNxXBeClT3g"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def padding_src_en(sentences_src, seq_len):\n",
        "    features_src = np.ones((len(sentences_src), seq_len), dtype=int)\n",
        "    for ii, sentences in enumerate(sentences_src):\n",
        "        features_src[ii, 0:len(sentences)] = np.array(sentences)[:seq_len]\n",
        "        features_src[ii, len(sentences) - 1] = 1\n",
        "        features_src[ii, -1] = 3\n",
        "    return features_src\n",
        "\n",
        "\n",
        "def padding_target_vn(sentences_tag, seq_len):\n",
        "    # padding for y_train list sequences VietNamese\n",
        "    # Thêm đệm cho các câu dữ liệu Tiếng Việt\n",
        "    features_tag = np.ones((len(sentences_tag), seq_len), dtype=int)\n",
        "    for ii, sentences in enumerate(sentences_tag):\n",
        "        features_tag[ii, 0:len(sentences)] = np.array(sentences)[:seq_len]\n",
        "    return features_tag\n",
        "\n",
        "\n",
        "def get_batch(index, src_en, target_vn, batch_size):\n",
        "        batch_src = src_en[index: index + batch_size]\n",
        "        batch_target = target_vn[index: index + batch_size]\n",
        "        max_seq_len_src = len(batch_src[-1])\n",
        "        max_seq_len_target = max([len(i) for i in batch_target])\n",
        "        batch_src = padding_src_en(batch_src, max_seq_len_src)\n",
        "        batch_target = padding_target_vn(batch_target, max_seq_len_target)\n",
        "        return batch_src, batch_target"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08OzbYePlYs0"
      },
      "source": [
        "\"\"\"\n",
        "load dataset\n",
        "\"\"\"\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "def read_file(file_name):\n",
        "    # return list VietNamese sentences, list English sentences\n",
        "    # đưa ra chuỗi tiếng anh và bản dịch tiếng việt tương ứng\n",
        "    with open(file_name + \"train.vi\", 'r', encoding='utf8') as file:\n",
        "        vn_list = file.readlines()\n",
        "    list_vn = [n.replace('\\n', '').lower() for n in vn_list]\n",
        "\n",
        "    with open(file_name + \"train.en\", 'r', encoding='utf8') as file:\n",
        "        en_list = file.readlines()\n",
        "    list_en = [n.replace('\\n', '').lower() for n in en_list]\n",
        "    return list_en, list_vn\n",
        "\n",
        "\n",
        "def split_dataset(x, y):\n",
        "    # split dataset\n",
        "    # Chia dữ liệu thành hai thành phần: dữ liệu huấn luyện và dữ liệu đánh giá\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.1,\n",
        "                                                      random_state=42)\n",
        "    return x_train, x_val, y_train, y_val\n",
        "\n",
        "\n",
        "def preprocess_string(s):\n",
        "    # preprocess string\n",
        "    # hàm xử lý chuỗi string s\n",
        "    # Remove all non-word characters (everything except numbers and letters)\n",
        "    # xoá các kí tự không phải là từ, ngoại trừ số và chữ cái\n",
        "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
        "    # Replace all runs of whitespaces with no space\n",
        "    # thay thế ccas khoảng trắng bằng không khoảng\n",
        "    s = re.sub(r\"\\s+\", '', s)\n",
        "    # replace digits with no space\n",
        "    # xoá các chữ số thành các khoảng trắng\n",
        "    s = re.sub(r\"\\d\", '', s)\n",
        "    return s\n",
        "\n",
        "\n",
        "def tokenize(en_train, vi_train):\n",
        "    # return dictionary english and dictionary vietnamese\n",
        "    # Đưa ra tập từ điển Tiếng Anh và tập từ điển Tiếng Việt từ bộ dữ\n",
        "    vocab_en = []\n",
        "    vocab_vn = []\n",
        "    for sent in en_train:\n",
        "        for word in sent.split():\n",
        "            word = preprocess_string(word)\n",
        "            if word != '':\n",
        "                vocab_en.append(word)\n",
        "    for sent in vi_train:\n",
        "        for word in sent.split():\n",
        "            word = preprocess_string(word)\n",
        "            if word != '':\n",
        "                vocab_vn.append(word)\n",
        "    # return 10000 word max frequent\n",
        "    # Đưa ra 10000 từ phổ biến nhất xuất hiện trong dữ liệu\n",
        "    corpus_en = Counter(vocab_en)\n",
        "    corpus_en = sorted(corpus_en, key=corpus_en.get, reverse=True)[:10000]\n",
        "    corpus_vn = Counter(vocab_vn)\n",
        "    corpus_vn = sorted(corpus_vn, key=corpus_vn.get, reverse=True)[:10000]\n",
        "\n",
        "    return corpus_en, corpus_vn\n",
        "\n",
        "\n",
        "def dict_laguage(en_train, vn_train):\n",
        "    # add index <unk>, <sos>, <pad>, <eos> into vocab english and vietnamese\n",
        "    # Thêm các kí tự đặc biệt vào tập từ điển tiếng Anh và tiếng Việt\n",
        "    corpus_en, corpus_vn = tokenize(en_train, vn_train)\n",
        "    en_dict = {w: i + 4 for i, w in enumerate(corpus_en)}\n",
        "    en_dict['<unk>'], en_dict['<pad>'], en_dict['<sos>'], en_dict['<eos>'] = 0, 1, 2, 3\n",
        "    vn_dict = {w: i + 4 for i, w in enumerate(corpus_vn)}\n",
        "    vn_dict['<unk>'], vn_dict['<pad>'], vn_dict['<sos>'], vn_dict['<eos>'] = 0, 1, 2, 3\n",
        "    return en_dict, vn_dict\n",
        "\n",
        "\n",
        "def word_to_index(sentences, vocab):\n",
        "    # return word in sentences to index and index to word\n",
        "    # Chuyển đổi câu thành index và ngược lại chuyển đổi index thành một câu\n",
        "    list_w_to_index = []\n",
        "    list_index_to_w = []\n",
        "    punc = '''!()-[]{};:'\"\\, <>./?@#$%^&*_~'''\n",
        "    for sent in sentences:\n",
        "        list_sent_1 = [2]\n",
        "        list_sent_2 = ['<sos>']\n",
        "        for word in sent.split():\n",
        "            # Nếu các từ không phải là dấu câu và thuộc trong tập từ điển\n",
        "            if word not in punc and preprocess_string(word) in vocab.keys():\n",
        "                list_sent_1.append(vocab[preprocess_string(word)])\n",
        "                list_sent_2.append(preprocess_string(word))\n",
        "            # Nếu các từ không phải là dấu câu và không thuộc trong tập từ điển\n",
        "            if word not in punc and preprocess_string(word) not in vocab.keys():\n",
        "                list_sent_1.append(vocab['<unk>'])\n",
        "                list_sent_2.append(preprocess_string(word))\n",
        "        list_sent_1.append(3)\n",
        "        list_sent_2.append('<eos>')\n",
        "        list_w_to_index.append(list_sent_1)\n",
        "        list_index_to_w.append(list_sent_2)\n",
        "    return list_w_to_index, list_index_to_w\n",
        "\n",
        "\n",
        "def encode_data(x_train, x_val, y_train, y_val, en_dict, vn_dict):\n",
        "    # return encode sentences to index in English train/valid data\n",
        "    # mã hoá dữ liệu các câu Tiếng Anh sang index trong tập từ điển Tiếng Anh\n",
        "    list_en_train_index, list_en_train_word = word_to_index(x_train, en_dict)\n",
        "    list_en_val_index, list_en_val_word = word_to_index(x_val, en_dict)\n",
        "    # return encode sentences to index in VietNamese train/valid data\n",
        "    # mã hoá các câu Tiếng Việt sang index trong tập từ điển Tiếng Việt\n",
        "    list_vn_train_index, list_vn_train_word = word_to_index(y_train, vn_dict)\n",
        "    list_vn_val_index, list_vn_val_word = word_to_index(y_val, vn_dict)\n",
        "    # return list_en_train_index, list_en_val_index, list_vn_train_index, list_vn_val_index\n",
        "    return list_en_train_index, list_vn_train_index, list_en_val_index, list_vn_val_index\n",
        "\n",
        "\n",
        "def filter_data(x, y, min_len, max_len):\n",
        "    x_filter = []\n",
        "    y_filter = []\n",
        "    for i in range(len(x)):\n",
        "        if min_len <= len(x[i]) <= max_len:\n",
        "            x_filter.append(x[i])\n",
        "            y_filter.append(y[i])\n",
        "    return x_filter, y_filter\n",
        "\n",
        "\n",
        "def sort_data_length(x, y):\n",
        "    pair = zip(x, y)\n",
        "    a, b = zip(*sorted(pair, key=lambda k: len(k[0])))\n",
        "    return a, b\n",
        "\n",
        "\n",
        "def filter_sentences(x_train, x_val, y_train, y_val, en_dict, vn_dict):\n",
        "    list_en_train_index, list_vn_train_index, list_en_val_index, list_vn_val_index = \\\n",
        "        encode_data(x_train, x_val, y_train, y_val, en_dict, vn_dict)\n",
        "    # filter data train and data valid min len 3 and max len 100\n",
        "    # Lấy các câu trong tập dữ liệu huấn luyện và trong tập dữ liệu kiểm tra có độ dài tối thiểu là 3 và tối đa là 100\n",
        "    list_en_train_index, list_vn_train_index = filter_data(list_en_train_index, list_vn_train_index, min_len=3,\n",
        "                                                           max_len=100)\n",
        "    list_en_val_index, list_vn_val_index = filter_data(list_en_val_index, list_vn_val_index, min_len=3, max_len=100)\n",
        "    list_en_train_index, list_vn_train_index = sort_data_length(list_en_train_index, list_vn_train_index)\n",
        "    list_en_val_index, list_vn_val_index = sort_data_length(list_en_val_index, list_vn_val_index)\n",
        "\n",
        "    return list_en_train_index, list_vn_train_index, list_en_val_index, list_vn_val_index\n",
        "\n",
        "\n",
        "def save_dict(obj, name):\n",
        "    with open(path + name + '.pkl', 'wb') as f:\n",
        "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "def load_dict(name):\n",
        "    with open(path + name + '.pkl', 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPUw9HxHlkml",
        "outputId": "99f39616-6265-417d-d63c-0d4dd7a63c21"
      },
      "source": [
        "# path\n",
        "path = \"/content/gdrive/MyDrive/machine_translation/neural_machine_translation/data/train_en2vi/\"\n",
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "class Experiment:\n",
        "    def __init__(self, learning_rate=0.001, num_epochs=100, encoder_embedding_size=300,\n",
        "                 decoder_embedding_size=300, hidden_size=1024, num_layers=2, drop_out=0.5, batch_size=32):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_epochs = num_epochs\n",
        "        self.encoder_embedding_size = encoder_embedding_size\n",
        "        self.decoder_embedding_size = decoder_embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.drop_out = drop_out\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def load_pickle(self, name):\n",
        "        with open(path + name + '.pkl', 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "    def evaluate(self, model, data_src, data_target):\n",
        "        pass\n",
        "\n",
        "    def translate_sentences(self, model, sentences, english_vocab, vietnamese_vocab, max_length):\n",
        "        list_w_to_index = [2]\n",
        "        for word in sentences.split():\n",
        "            word = word.lower()\n",
        "            if preprocess_string(word) in english_vocab.keys():\n",
        "                list_w_to_index.append(english_vocab[preprocess_string(word)])\n",
        "            if preprocess_string(word) not in english_vocab.keys():\n",
        "                list_w_to_index.append(english_vocab['<unk>'])\n",
        "        list_w_to_index.append(3)\n",
        "        sentences_tensor = torch.LongTensor(list_w_to_index).unsqueeze(1).to(device)\n",
        "        with torch.no_grad():\n",
        "            hidden, cell = model.Encoder_LSTM(sentences_tensor)\n",
        "        outputs = [2]\n",
        "        for _ in range(max_length):\n",
        "            previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                output, hidden, cell = model.Decoder_LSTM(previous_word, hidden, cell)\n",
        "                best_guess = output.argmax(1).item()\n",
        "\n",
        "            outputs.append(best_guess)\n",
        "            if output.argmax(1).item() == 3:\n",
        "                break\n",
        "        vietnamese_vocab = {v: k for k, v in vietnamese_vocab.items()}\n",
        "        translated_sentence = [vietnamese_vocab[idx] for idx in outputs]\n",
        "        return translated_sentence\n",
        "\n",
        "    def bleu(self, model, english_vocab, vietnamese_vocab):\n",
        "        pass\n",
        "\n",
        "    def train_and_eval(self):\n",
        "        en_dictionary = self.load_pickle(\"en_dictionary\")\n",
        "        vn_dictionary = self.load_pickle(\"vn_dictionary\")\n",
        "        dict_train_val = self.load_pickle(\"dict_train_val\")\n",
        "        list_en_train_index, list_vn_train_index = list(dict_train_val['list_en_train_index']), \\\n",
        "                                                   list(dict_train_val['list_vn_train_index'])\n",
        "        list_en_val_index, list_vn_val_index = list(dict_train_val['list_en_val_index']), \\\n",
        "                                               list(dict_train_val['list_vn_val_index'])\n",
        "\n",
        "        encoder_lstm = EncoderLSTM(len(en_dictionary), self.encoder_embedding_size,\n",
        "                                   self.hidden_size, self.num_layers, self.drop_out).to(device)\n",
        "        decoder_lstm = DecoderLSTM(len(vn_dictionary), self.decoder_embedding_size,\n",
        "                                   self.hidden_size, self.num_layers, self.drop_out, len(vn_dictionary)).to(device)\n",
        "        model = Seq2Seq(encoder_lstm, decoder_lstm).to(device)\n",
        "        opt = torch.optim.Adam(model.parameters(), lr=self.learning_rate)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        sentences_1 = \"I go to school by bus\"\n",
        "        print(\"Starting training...\")\n",
        "        for it in range(1, self.num_epochs + 1):\n",
        "            model.eval()\n",
        "            translated_sentence1 = self.translate_sentences(model, sentences_1, en_dictionary, vn_dictionary, 50)\n",
        "            print(\"Translate sentence 1: {}\".format(translated_sentence1))\n",
        "            model.train()\n",
        "            losses = []\n",
        "            for j in range(0, len(list_en_train_index), self.batch_size):\n",
        "                src_batch_en, target_batch_vn = get_batch(j, list_en_train_index, list_vn_train_index, self.batch_size)\n",
        "                src_batch_en = torch.Tensor(src_batch_en).to(torch.int64).T\n",
        "                target_batch_vn = torch.Tensor(target_batch_vn).to(torch.int64).T\n",
        "                src_batch_en = src_batch_en.to(device)\n",
        "                target_batch_vn = target_batch_vn.to(device)\n",
        "                # print(src_batch_en.shape)\n",
        "                # print(target_batch_vn.shape)\n",
        "                # Pass the input and target for model's forward method\n",
        "                output = model(src_batch_en, target_batch_vn)\n",
        "                output = output[1:].reshape(-1, output.shape[2])\n",
        "                target = target_batch_vn[1:].reshape(-1)\n",
        "                # Clear the accumulating gradients\n",
        "                opt.zero_grad()\n",
        "                # Calculate the loss value for every epoch\n",
        "                loss = criterion(output, target)\n",
        "                # Calculate the gradients for weights & biases using back-propagation\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "                losses.append(loss.item())\n",
        "            print(\"Epoch: {}\".format(it))\n",
        "            print(\"Loss: {}\".format(np.mean(losses)))\n",
        "            model.eval()\n",
        "            # with torch.no_grad():\n",
        "            #    print(\"Validation:\")\n",
        "            #     self.evaluate(model, list_en_val_index, list_vn_val_index)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    experiment = Experiment(learning_rate=0.001, num_epochs=100, encoder_embedding_size=300,\n",
        "                            decoder_embedding_size=300, hidden_size=1024, num_layers=2, drop_out=0.5, batch_size=100)\n",
        "    experiment.train_and_eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "Translate sentence 1: ['<sos>', 'loai', 'ràng', 'namibia', 'dewar', 'khoát', 'ooh', 'ooh', 'caltrans', 'ab', 'rảnh', 'anil', 'anil', 'eduardo', 'cedarssinai', 'cedarssinai', 'cedarssinai', 'nón', 'lụi', 'lụi', 'lụi', 'đạp', 'đạp', 'bound', 'bound', 'càn', 'càn', 'aberdeen', 'aberdeen', 'panô', 'panô', 'panô', 'rồng', 'mujahideen', 'gặt', 'gặt', 'erin', 'erin', 'nhược', 'glenn', 'glenn', 'bosch', 'glenn', 'bosch', 'brin', 'brin', 'brin', 'brin', 'fusion', 'bụi', 'fusion']\n",
            "Epoch: 1\n",
            "Loss: 3.6875191235383085\n",
            "Translate sentence 1: ['<sos>', 'khi', 'tôi', 'bắt', 'đầu', 'với', 'những', 'người', 'của', 'mình', 'và', 'những', 'người', 'của', 'mình', 'và', 'những', 'người', 'của', 'mình', 'và', 'những', 'người', 'người', 'đã', 'làm', 'việc', 'với', 'những', 'người', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Epoch: 2\n",
            "Loss: 3.208450211308436\n",
            "Translate sentence 1: ['<sos>', 'tôi', 'cố', 'gắng', 'tìm', 'kiếm', 'những', 'cách', 'của', 'mình', '<eos>']\n",
            "Epoch: 3\n",
            "Loss: 3.0002145431873597\n",
            "Translate sentence 1: ['<sos>', 'tôi', 'đi', 'đến', 'với', 'với', 'những', '<eos>']\n",
            "Epoch: 4\n",
            "Loss: 2.8677631574301965\n",
            "Translate sentence 1: ['<sos>', 'tôi', 'đi', 'đến', 'với', 'với', 'các', 'nhà', '<eos>']\n",
            "Epoch: 5\n",
            "Loss: 2.7759975851676697\n",
            "Translate sentence 1: ['<sos>', 'tôi', 'đi', 'đến', 'trường', 'học', '<eos>']\n",
            "Epoch: 6\n",
            "Loss: 2.687966922736526\n",
            "Translate sentence 1: ['<sos>', 'tôi', 'đi', 'đến', 'trường', 'học', '<eos>']\n",
            "Epoch: 7\n",
            "Loss: 2.62065541943246\n",
            "Translate sentence 1: ['<sos>', 'tôi', 'đến', 'trường', 'học', 'trường', '<eos>']\n",
            "Epoch: 8\n",
            "Loss: 2.5678428823939945\n",
            "Translate sentence 1: ['<sos>', 'tôi', 'đi', 'đến', 'trường', 'barefoot', '<eos>']\n",
            "Epoch: 9\n",
            "Loss: 2.5189299853596343\n",
            "Translate sentence 1: ['<sos>', 'tôi', 'đi', 'đến', 'trường', 'để', 'mua', 'xe', 'đạp', '<eos>']\n",
            "Epoch: 10\n",
            "Loss: 2.4659768370087436\n",
            "Translate sentence 1: ['<sos>', 'tôi', 'đi', 'đến', 'trường', '<eos>']\n",
            "Epoch: 11\n",
            "Loss: 2.434409837790443\n",
            "Translate sentence 1: ['<sos>', 'tôi', 'đi', 'học', 'về', 'nhà', '<eos>']\n",
            "Epoch: 12\n",
            "Loss: 2.398546675136173\n",
            "Translate sentence 1: ['<sos>', 'tôi', 'đi', 'học', 'về', 'nhà', '<eos>']\n"
          ]
        }
      ]
    }
  ]
}